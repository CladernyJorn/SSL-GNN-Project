{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Effect of Saint Sampler\n",
    "(Not fully implemented yet)\n",
    "\n",
    "This is a presentation document that tests the effects of the Saint Sampler method on the cora dataset of GRACE and GraphMAE.\n",
    "\n",
    "First define training functions for convenience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_GraphMAE import train_eval_whole_graph,train_eval_batch_sampler\n",
    "from graphmae.utils import load_best_configs\n",
    "import argparse\n",
    "\n",
    "def build_args():\n",
    "    parser = argparse.ArgumentParser(description=\"GAT\")\n",
    "    parser.add_argument(\"--seeds\", type=int, nargs=\"+\", default=[0])\n",
    "    parser.add_argument(\"--dataset\", type=str, default=\"cora\")\n",
    "    parser.add_argument(\"--device\", type=int, default=-1)\n",
    "    parser.add_argument(\"--max_epoch\", type=int, default=200,\n",
    "                        help=\"number of training epochs\")\n",
    "    parser.add_argument(\"--warmup_steps\", type=int, default=-1)\n",
    "\n",
    "    parser.add_argument(\"--num_heads\", type=int, default=4,\n",
    "                        help=\"number of hidden attention heads\")\n",
    "    parser.add_argument(\"--num_out_heads\", type=int, default=1,\n",
    "                        help=\"number of output attention heads\")\n",
    "    parser.add_argument(\"--num_layers\", type=int, default=2,\n",
    "                        help=\"number of hidden layers\")\n",
    "    parser.add_argument(\"--num_hidden\", type=int, default=256,\n",
    "                        help=\"number of hidden units\")\n",
    "    parser.add_argument(\"--residual\", action=\"store_true\", default=False,\n",
    "                        help=\"use residual connection\")\n",
    "    parser.add_argument(\"--in_drop\", type=float, default=.2,\n",
    "                        help=\"input feature dropout\")\n",
    "    parser.add_argument(\"--attn_drop\", type=float, default=.1,\n",
    "                        help=\"attention dropout\")\n",
    "    parser.add_argument(\"--norm\", type=str, default=None)\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.005,\n",
    "                        help=\"learning rate\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4,\n",
    "                        help=\"weight decay\")\n",
    "    parser.add_argument(\"--negative_slope\", type=float, default=0.2,\n",
    "                        help=\"the negative slope of leaky relu for GAT\")\n",
    "    parser.add_argument(\"--activation\", type=str, default=\"prelu\")\n",
    "    parser.add_argument(\"--mask_rate\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--drop_edge_rate\", type=float, default=0.0)\n",
    "    parser.add_argument(\"--replace_rate\", type=float, default=0.0)\n",
    "\n",
    "    parser.add_argument(\"--encoder\", type=str, default=\"gat\")\n",
    "    parser.add_argument(\"--decoder\", type=str, default=\"gat\")\n",
    "    parser.add_argument(\"--loss_fn\", type=str, default=\"sce\")\n",
    "    parser.add_argument(\"--alpha_l\", type=float, default=2, help=\"`pow`coefficient for `sce` loss\")\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"adam\")\n",
    "\n",
    "    parser.add_argument(\"--max_epoch_f\", type=int, default=30)\n",
    "    parser.add_argument(\"--lr_f\", type=float, default=0.001, help=\"learning rate for evaluation\")\n",
    "    parser.add_argument(\"--weight_decay_f\", type=float, default=0.0, help=\"weight decay for evaluation\")\n",
    "    parser.add_argument(\"--linear_prob\", action=\"store_true\", default=False)\n",
    "\n",
    "    parser.add_argument(\"--load_model\", action=\"store_true\")\n",
    "    parser.add_argument(\"--save_model\", action=\"store_true\")\n",
    "    parser.add_argument(\"--use_cfg\", action=\"store_true\")\n",
    "    parser.add_argument(\"--logging\", action=\"store_true\")\n",
    "    parser.add_argument(\"--scheduler\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--concat_hidden\", action=\"store_true\", default=False)\n",
    "\n",
    "    # graph sample + mini-batch\n",
    "    parser.add_argument(\"--use_sampler\",action=\"store_true\",default=False)\n",
    "    parser.add_argument(\"--budget\", type=int, default=500,help=\"number of nodes sampled per batch with SaintSampler\")\n",
    "    parser.add_argument(\"--num_iters\", type=int, default=0,help=\"number of iters to train ( default= max_epoch*total_nodes_num/budget )\")\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "def run_cora_test_on_graphmae(budget_list):\n",
    "\targs = build_args()\n",
    "\targs.dataset='cora'\n",
    "\targs = load_best_configs(args, \"./configs/best_GraphMAE_configs.yml\")\n",
    "\targs.use_sampler=True\n",
    "\targs.num_iters=0\n",
    "\targs.device=0\n",
    "    \n",
    "\targs.encoder='gat'\n",
    "\targs.decoder='gat'\n",
    "\tacc_list=[]\n",
    "\tfor budget in budget_list:\n",
    "\t\targs.budget=budget\n",
    "\t\tprint(args)\n",
    "\t\tacc=train_eval_batch_sampler(args)\n",
    "\t\tacc_list.append(acc)\n",
    "\tacc_list.append(train_eval_whole_graph(args))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from main_Grace import train_eval_whole_graph,train_eval_batch_sampler\n",
    "from grace.utils import load_best_configs\n",
    "import argparse\n",
    "\n",
    "def build_args_2():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--seeds\", type=int, nargs=\"+\", default=[0])\n",
    "    parser.add_argument('--dataset', type=str, default='cora')\n",
    "    parser.add_argument(\"--device\", type=int, default=-1)\n",
    "    parser.add_argument(\"--use_cfg\", action=\"store_true\")\n",
    "\n",
    "    parser.add_argument(\"--encoder\", type=str, default=\"gcn\")\n",
    "    parser.add_argument(\"--activation\", type=str, default=\"relu\")\n",
    "\n",
    "    parser.add_argument(\"--drop_edge_rate_1\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--drop_edge_rate_2\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--drop_feature_rate_1\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--drop_feature_rate_2\", type=float, default=0.5)\n",
    "    parser.add_argument(\"--tau\", type=float, default=0.5)\n",
    "\n",
    "    parser.add_argument(\"--num_hidden\", type=int, default=256,\n",
    "                        help=\"number of hidden units\")\n",
    "    parser.add_argument(\"--num_proj_hidden\", type=int, default=256,\n",
    "                        help=\"number of hidden units\")\n",
    "    parser.add_argument(\"--num_layers\", type=int, default=2,\n",
    "                        help=\"number of hidden layers\")\n",
    "\n",
    "\n",
    "    parser.add_argument(\"--num_heads\", type=int, default=4,\n",
    "                        help=\"number of hidden attention heads\")\n",
    "    parser.add_argument(\"--lr\", type=float, default=0.005,\n",
    "                        help=\"learning rate\")\n",
    "    parser.add_argument(\"--weight_decay\", type=float, default=5e-4,\n",
    "                        help=\"weight decay\")\n",
    "    parser.add_argument(\"--optimizer\", type=str, default=\"adam\")\n",
    "    parser.add_argument(\"--scheduler\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--max_epoch\", type=int, default=200,\n",
    "                        help=\"number of training epochs\")\n",
    "    parser.add_argument(\"--max_epoch_f\", type=int, default=300)\n",
    "    parser.add_argument(\"--lr_f\", type=float, default=0.001, help=\"learning rate for evaluation\")\n",
    "    parser.add_argument(\"--weight_decay_f\", type=float, default=0.0, help=\"weight decay for evaluation\")\n",
    "    parser.add_argument(\"--linear_prob\", action=\"store_true\", default=True)\n",
    "\n",
    "    parser.add_argument(\"--logging\", action=\"store_true\")\n",
    "    parser.add_argument(\"--load_model\", action=\"store_true\")\n",
    "    parser.add_argument(\"--save_model\", action=\"store_true\")\n",
    "    # graph sample + mini-batch\n",
    "    parser.add_argument(\"--use_sampler\", action=\"store_true\", default=False)\n",
    "    parser.add_argument(\"--budget\", type=int, default=500, help=\"number of nodes sampled per batch with SaintSampler\")\n",
    "    parser.add_argument(\"--num_iters\", type=int, default=0,\n",
    "                        help=\"number of iters to train ( default= max_epoch*total_nodes_num/budget )\")\n",
    "\n",
    "    args = parser.parse_args(args=[])\n",
    "    return args\n",
    "\n",
    "def run_cora_test_on_grace(budget_list):\n",
    "\targs = build_args_2()\n",
    "\targs.dataset='cora'\n",
    "\targs = load_best_configs(args, \"./configs/best_GraphMAE_configs.yml\")\n",
    "\targs.use_sampler=True\n",
    "\targs.num_iters=0\n",
    "\targs.device=0\n",
    "\targs.encoder='gat'\n",
    "\tacc_list=[]\n",
    "\tfor budget in budget_list:\n",
    "\t\targs.budget=budget\n",
    "\t\tprint(args)\n",
    "\t\tacc=train_eval_batch_sampler(args)\n",
    "\t\tacc_list.append(acc)\n",
    "\tacc_list.append(train_eval_whole_graph(args))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Then train\n",
    "For fairness in comparison, the number of training sessions is set to the default value: $ N(graph_{full})\\times epochs/ budget$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-09 14:25:10,467 - INFO - Using best configs\n",
      "2023-04-09 14:25:10,534 - INFO - Use schedular\n",
      "2023-04-09 14:25:10,535 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------ Use best configs ------\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=500, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 203: train_loss: 6.4301:  12%|█▎        | 203/1624 [00:11<03:39,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6280, early-stopping-TestAcc: 0.6280, Best ValAcc: 0.6500 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 403: train_loss: 6.3536:  25%|██▍       | 403/1624 [00:23<02:41,  7.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6440, early-stopping-TestAcc: 0.6440, Best ValAcc: 0.6480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 602: train_loss: 6.3621:  37%|███▋      | 601/1624 [00:35<03:47,  4.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7230, early-stopping-TestAcc: 0.7190, Best ValAcc: 0.7100 in epoch 162 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 803: train_loss: 6.3357:  49%|████▉     | 803/1624 [00:46<02:11,  6.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7430, early-stopping-TestAcc: 0.7330, Best ValAcc: 0.7400 in epoch 81 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1002: train_loss: 6.3813:  62%|██████▏   | 1003/1624 [00:58<01:34,  6.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7500, early-stopping-TestAcc: 0.7300, Best ValAcc: 0.7420 in epoch 62 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1202: train_loss: 6.2759:  74%|███████▍  | 1202/1624 [01:11<01:04,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7660, early-stopping-TestAcc: 0.7560, Best ValAcc: 0.7640 in epoch 172 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1402: train_loss: 6.1866:  86%|████████▋ | 1403/1624 [01:23<00:36,  6.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7730, early-stopping-TestAcc: 0.7710, Best ValAcc: 0.7540 in epoch 137 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1603: train_loss: 6.2824:  99%|█████████▊| 1603/1624 [01:35<00:03,  6.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7730, early-stopping-TestAcc: 0.7730, Best ValAcc: 0.7580 in epoch 246 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1623: train_loss: 6.1657: 100%|██████████| 1624/1624 [01:36<00:00, 16.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5732, val_loss: 0.7723, val_acc:0.75, test_loss: 0.7194, test_acc: 0.7720: 100%|██████████| 300/300 [00:01<00:00, 194.65it/s] \n",
      "2023-04-09 14:26:48,864 - INFO - Use schedular\n",
      "2023-04-09 14:26:48,864 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7720, early-stopping-TestAcc: 0.7680, Best ValAcc: 0.7520 in epoch 201 --- \n",
      "# final_acc: 0.7720±0.0000\n",
      "# early-stopping_acc: 0.7680±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=1000, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 203: train_loss: 6.7790:  25%|██▍       | 202/812 [00:12<01:39,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7470, early-stopping-TestAcc: 0.7470, Best ValAcc: 0.7440 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 6.7432:  50%|████▉     | 402/812 [00:24<01:06,  6.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7540, early-stopping-TestAcc: 0.7540, Best ValAcc: 0.7580 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 602: train_loss: 6.6163:  74%|███████▍  | 602/812 [00:37<00:35,  5.90it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7790, early-stopping-TestAcc: 0.7720, Best ValAcc: 0.7680 in epoch 87 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 802: train_loss: 6.4932:  99%|█████████▉| 802/812 [00:50<00:01,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7760, early-stopping-TestAcc: 0.7680, Best ValAcc: 0.7560 in epoch 69 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 811: train_loss: 6.5902: 100%|██████████| 812/812 [00:50<00:00, 16.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5919, val_loss: 0.7626, val_acc:0.744, test_loss: 0.7322, test_acc: 0.7730: 100%|██████████| 300/300 [00:01<00:00, 192.60it/s]\n",
      "2023-04-09 14:27:41,246 - INFO - Use schedular\n",
      "2023-04-09 14:27:41,246 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7730, early-stopping-TestAcc: 0.7630, Best ValAcc: 0.7560 in epoch 58 --- \n",
      "# final_acc: 0.7730±0.0000\n",
      "# early-stopping_acc: 0.7630±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=1500, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 202: train_loss: 7.1577:  37%|███▋      | 202/541 [00:12<00:55,  6.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6930, early-stopping-TestAcc: 0.6930, Best ValAcc: 0.6880 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 7.0796:  74%|███████▍  | 402/541 [00:25<00:22,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7250, early-stopping-TestAcc: 0.7250, Best ValAcc: 0.7280 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 540: train_loss: 6.8978: 100%|██████████| 541/541 [00:34<00:00, 15.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5929, val_loss: 0.7531, val_acc:0.762, test_loss: 0.7345, test_acc: 0.7590: 100%|██████████| 300/300 [00:01<00:00, 179.28it/s]\n",
      "2023-04-09 14:28:17,106 - INFO - Use schedular\n",
      "2023-04-09 14:28:17,106 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7590, early-stopping-TestAcc: 0.7570, Best ValAcc: 0.7720 in epoch 170 --- \n",
      "# final_acc: 0.7590±0.0000\n",
      "# early-stopping_acc: 0.7570±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=2000, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 202: train_loss: 7.1429:  50%|████▉     | 202/406 [00:13<00:34,  5.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7510, early-stopping-TestAcc: 0.7510, Best ValAcc: 0.7480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 7.0656:  99%|█████████▉| 402/406 [00:27<00:00,  6.12it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7590, early-stopping-TestAcc: 0.7590, Best ValAcc: 0.7480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 405: train_loss: 7.1126: 100%|██████████| 406/406 [00:27<00:00, 14.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5800, val_loss: 0.7886, val_acc:0.746, test_loss: 0.7514, test_acc: 0.7580: 100%|██████████| 300/300 [00:01<00:00, 192.85it/s]\n",
      "2023-04-09 14:28:46,259 - INFO - Use schedular\n",
      "2023-04-09 14:28:46,259 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7580, early-stopping-TestAcc: 0.7580, Best ValAcc: 0.7460 in epoch 299 --- \n",
      "# final_acc: 0.7580±0.0000\n",
      "# early-stopping_acc: 0.7580±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=2708, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 201: train_loss: 7.4035:  67%|██████▋   | 202/300 [00:14<00:19,  4.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7150, early-stopping-TestAcc: 0.7150, Best ValAcc: 0.6800 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 299: train_loss: 7.4170: 100%|██████████| 300/300 [00:21<00:00, 13.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.7207, val_loss: 0.8567, val_acc:0.688, test_loss: 0.8572, test_acc: 0.7280: 100%|██████████| 300/300 [00:01<00:00, 193.39it/s]\n",
      "2023-04-09 14:29:09,405 - INFO - Use schedular\n",
      "2023-04-09 14:29:09,406 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7280, early-stopping-TestAcc: 0.7280, Best ValAcc: 0.6900 in epoch 294 --- \n",
      "# final_acc: 0.7280±0.0000\n",
      "# early-stopping_acc: 0.7280±0.0000\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 201: train_loss: 7.7524:  67%|██████▋   | 200/300 [00:18<00:28,  3.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7550, early-stopping-TestAcc: 0.7520, Best ValAcc: 0.7440 in epoch 219 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 299: train_loss: 7.7332: 100%|██████████| 300/300 [00:27<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5523, val_loss: 0.8024, val_acc:0.738, test_loss: 0.7488, test_acc: 0.7560: 100%|██████████| 300/300 [00:01<00:00, 165.06it/s]\n",
      "2023-04-09 14:29:38,985 - INFO - Using best configs\n",
      "2023-04-09 14:29:39,090 - INFO - Use schedular\n",
      "2023-04-09 14:29:39,091 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7560, early-stopping-TestAcc: 0.7560, Best ValAcc: 0.7400 in epoch 297 --- \n",
      "# final_acc: 0.7560±0.0000\n",
      "# early-stopping_acc: 0.7560±0.0000\n",
      "------ Use best configs ------\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=500, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 202: train_loss: 6.5135:  12%|█▏        | 202/1624 [00:14<04:15,  5.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6280, early-stopping-TestAcc: 0.6280, Best ValAcc: 0.6500 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 6.5248:  25%|██▍       | 402/1624 [00:27<03:39,  5.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6440, early-stopping-TestAcc: 0.6440, Best ValAcc: 0.6480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 602: train_loss: 6.3621:  37%|███▋      | 602/1624 [00:40<02:57,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7230, early-stopping-TestAcc: 0.7190, Best ValAcc: 0.7100 in epoch 162 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 802: train_loss: 6.2566:  49%|████▉     | 802/1624 [00:54<02:24,  5.68it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7430, early-stopping-TestAcc: 0.7330, Best ValAcc: 0.7400 in epoch 81 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1002: train_loss: 6.3813:  62%|██████▏   | 1002/1624 [01:07<01:48,  5.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7500, early-stopping-TestAcc: 0.7300, Best ValAcc: 0.7420 in epoch 62 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1202: train_loss: 6.2759:  74%|███████▍  | 1202/1624 [01:19<01:13,  5.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7660, early-stopping-TestAcc: 0.7560, Best ValAcc: 0.7640 in epoch 172 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1402: train_loss: 6.1866:  86%|████████▋ | 1403/1624 [01:33<00:39,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7730, early-stopping-TestAcc: 0.7710, Best ValAcc: 0.7540 in epoch 137 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1602: train_loss: 6.1626:  99%|█████████▊| 1603/1624 [01:46<00:03,  5.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7730, early-stopping-TestAcc: 0.7730, Best ValAcc: 0.7580 in epoch 246 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 1623: train_loss: 6.1657: 100%|██████████| 1624/1624 [01:47<00:00, 15.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5732, val_loss: 0.7723, val_acc:0.75, test_loss: 0.7194, test_acc: 0.7720: 100%|██████████| 300/300 [00:01<00:00, 191.93it/s] \n",
      "2023-04-09 14:31:28,321 - INFO - Use schedular\n",
      "2023-04-09 14:31:28,322 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7720, early-stopping-TestAcc: 0.7680, Best ValAcc: 0.7520 in epoch 201 --- \n",
      "# final_acc: 0.7720±0.0000\n",
      "# early-stopping_acc: 0.7680±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=1000, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 202: train_loss: 6.7147:  25%|██▍       | 202/812 [00:13<01:47,  5.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7470, early-stopping-TestAcc: 0.7470, Best ValAcc: 0.7440 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 6.7432:  50%|████▉     | 402/812 [00:26<01:10,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7540, early-stopping-TestAcc: 0.7540, Best ValAcc: 0.7580 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 602: train_loss: 6.6163:  74%|███████▍  | 602/812 [00:39<00:34,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7790, early-stopping-TestAcc: 0.7720, Best ValAcc: 0.7680 in epoch 87 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 802: train_loss: 6.4932:  99%|█████████▉| 802/812 [00:52<00:01,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7760, early-stopping-TestAcc: 0.7680, Best ValAcc: 0.7560 in epoch 69 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 811: train_loss: 6.5902: 100%|██████████| 812/812 [00:53<00:00, 15.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5919, val_loss: 0.7626, val_acc:0.744, test_loss: 0.7322, test_acc: 0.7730: 100%|██████████| 300/300 [00:01<00:00, 177.38it/s]\n",
      "2023-04-09 14:32:23,352 - INFO - Use schedular\n",
      "2023-04-09 14:32:23,352 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7730, early-stopping-TestAcc: 0.7630, Best ValAcc: 0.7560 in epoch 58 --- \n",
      "# final_acc: 0.7730±0.0000\n",
      "# early-stopping_acc: 0.7630±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=1500, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 201: train_loss: 7.1004:  37%|███▋      | 202/541 [00:14<01:15,  4.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.6930, early-stopping-TestAcc: 0.6930, Best ValAcc: 0.6880 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 7.0796:  74%|███████▍  | 402/541 [00:28<00:24,  5.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7250, early-stopping-TestAcc: 0.7250, Best ValAcc: 0.7280 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 540: train_loss: 6.8978: 100%|██████████| 541/541 [00:36<00:00, 14.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5929, val_loss: 0.7531, val_acc:0.762, test_loss: 0.7345, test_acc: 0.7590: 100%|██████████| 300/300 [00:01<00:00, 196.43it/s]\n",
      "2023-04-09 14:33:01,906 - INFO - Use schedular\n",
      "2023-04-09 14:33:01,907 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7590, early-stopping-TestAcc: 0.7570, Best ValAcc: 0.7720 in epoch 170 --- \n",
      "# final_acc: 0.7590±0.0000\n",
      "# early-stopping_acc: 0.7570±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=2000, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 202: train_loss: 7.1429:  50%|████▉     | 202/406 [00:13<00:35,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7510, early-stopping-TestAcc: 0.7510, Best ValAcc: 0.7480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 402: train_loss: 7.0656:  99%|█████████▉| 402/406 [00:27<00:00,  5.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7590, early-stopping-TestAcc: 0.7590, Best ValAcc: 0.7480 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 405: train_loss: 7.1126: 100%|██████████| 406/406 [00:27<00:00, 14.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5800, val_loss: 0.7886, val_acc:0.746, test_loss: 0.7514, test_acc: 0.7580: 100%|██████████| 300/300 [00:01<00:00, 188.26it/s]\n",
      "2023-04-09 14:33:31,413 - INFO - Use schedular\n",
      "2023-04-09 14:33:31,414 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7580, early-stopping-TestAcc: 0.7580, Best ValAcc: 0.7460 in epoch 299 --- \n",
      "# final_acc: 0.7580±0.0000\n",
      "# early-stopping_acc: 0.7580±0.0000\n",
      "Namespace(seeds=[0], dataset='cora', device=0, use_cfg=False, encoder='gat', activation='prelu', drop_edge_rate_1=0.5, drop_edge_rate_2=0.5, drop_feature_rate_1=0.5, drop_feature_rate_2=0.5, tau=0.5, num_hidden=512, num_proj_hidden=256, num_layers=2, num_heads=4, lr=0.001, weight_decay=0.0002, optimizer='adam', scheduler=True, max_epoch=300, max_epoch_f=300, lr_f=0.01, weight_decay_f=0.0001, linear_prob=True, logging=False, load_model=False, save_model=False, use_sampler=True, budget=2708, num_iters=0, mask_rate=0.5, decoder='gat', in_drop=0.2, attn_drop=0.1, loss_fn='sce', drop_edge_rate=0.0, replace_rate=0.05, alpha_l=3, num_features=1433)\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 201: train_loss: 7.4035:  67%|██████▋   | 202/300 [00:14<00:17,  5.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7150, early-stopping-TestAcc: 0.7150, Best ValAcc: 0.6800 in epoch 299 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Iters 299: train_loss: 7.4170: 100%|██████████| 300/300 [00:21<00:00, 13.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.7207, val_loss: 0.8567, val_acc:0.688, test_loss: 0.8572, test_acc: 0.7280: 100%|██████████| 300/300 [00:01<00:00, 186.92it/s]\n",
      "2023-04-09 14:33:54,691 - INFO - Use schedular\n",
      "2023-04-09 14:33:54,692 - INFO - start training..\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7280, early-stopping-TestAcc: 0.7280, Best ValAcc: 0.6900 in epoch 294 --- \n",
      "# final_acc: 0.7280±0.0000\n",
      "# early-stopping_acc: 0.7280±0.0000\n",
      "  NumNodes: 2708\n",
      "  NumEdges: 10556\n",
      "  NumFeats: 1433\n",
      "  NumClasses: 7\n",
      "  NumTrainingSamples: 140\n",
      "  NumValidationSamples: 500\n",
      "  NumTestSamples: 1000\n",
      "Done loading data from cached files.\n",
      "####### Run 0 for seed 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 201: train_loss: 7.7524:  67%|██████▋   | 201/300 [00:17<00:23,  4.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# IGNORE: --- TestAcc: 0.7550, early-stopping-TestAcc: 0.7520, Best ValAcc: 0.7440 in epoch 219 --- \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch 299: train_loss: 7.7332: 100%|██████████| 300/300 [00:26<00:00, 11.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num parameters for finetuning: 3591\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "# Epoch: 299, train_loss: 0.5523, val_loss: 0.8024, val_acc:0.738, test_loss: 0.7488, test_acc: 0.7560: 100%|██████████| 300/300 [00:01<00:00, 205.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- TestAcc: 0.7560, early-stopping-TestAcc: 0.7560, Best ValAcc: 0.7400 in epoch 297 --- \n",
      "# final_acc: 0.7560±0.0000\n",
      "# early-stopping_acc: 0.7560±0.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "budget_list=[500,1000,1500,2000,2708]\n",
    "result_graphmae=run_cora_test_on_graphmae(budget_list)\n",
    "result_grace=run_cora_test_on_grace(budget_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'NoneType' object is not subscriptable",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mC:\\WINDOWS\\TEMP/ipykernel_10092/3786459388.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbudget_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0my1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult_graphmae\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# Sample data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0my2\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresult_grace\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'constrained'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: 'NoneType' object is not subscriptable"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "x=budget_list\n",
    "y1 = result_graphmae[:-1]  # Sample data.\n",
    "y2=result_grace[:-1]\n",
    "plt.figure(figsize=(10, 5), layout='constrained')\n",
    "plt.plot(x, y1, label='GRACE')  # Plot some data on the (implicit) axes.\n",
    "plt.plot(x, y2, label='GraphMAE')  # etc.\n",
    "plt.axhline(result_graphmae[-1],label='GraphMAE (full graph)')\n",
    "plt.axhline(result_grace[-1],label='GRACE (full graph)')\n",
    "\n",
    "plt.xlabel('budget')\n",
    "plt.ylabel('acc')\n",
    "plt.title(\"Effect of Saint Sampler\")\n",
    "plt.legend()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5179d32cf6ec497baf3f8a3ef987cc77c5d2dc691fdde20a56316522f61a7323"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
